{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/fa926284/Documents/Parkinson_FOG_Detection/src\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from os.path import join, pardir, curdir\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from joblib import load, dump\n",
    "from sklearn.preprocessing import StandardScaler, label_binarize\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import average_precision_score, precision_score, classification_report\n",
    "\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set current directory to \"src\"\n",
    "os.chdir(join(os.getcwd(), os.pardir, \"src\"))\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n",
    "\n",
    "from feature_extractor import *\n",
    "from process import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total subjects: 924\n",
      "Train subjects: 905\n",
      "Validation subjects: 19\n",
      "Test subjects: 2\n"
     ]
    }
   ],
   "source": [
    "DATASETS = ['tdcsfog', 'defog']\n",
    "DATA_PATH = join(pardir, 'data')\n",
    "PROCESSED_DATA_PATH = join(pardir, \"data\", \"processed_dl\")\n",
    "FILE_DIRS = []\n",
    "TRAIN_DIRS = []\n",
    "VAL_DIRS = []\n",
    "TEST_DIRS = []\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "if not os.path.isdir(PROCESSED_DATA_PATH):\n",
    "    os.mkdir(PROCESSED_DATA_PATH)\n",
    "\n",
    "for dataset in DATASETS:\n",
    "    FILE_DIRS.extend(glob.glob(join(DATA_PATH, \"train\", dataset, \"*.csv\"))[:])\n",
    "    TEST_DIRS.extend(glob.glob(join(DATA_PATH, \"test\", dataset, \"*.csv\"))[:])\n",
    "TRAIN_DIRS, VAL_DIRS = random_split_list(FILE_DIRS,\n",
    "                                         random_seed=42,\n",
    "                                         split=0.98)\n",
    "\n",
    "print(f\"Total subjects: {len(FILE_DIRS)}\")\n",
    "print(f\"Train subjects: {len(TRAIN_DIRS)}\")\n",
    "print(f\"Validation subjects: {len(VAL_DIRS)}\")\n",
    "print(f\"Test subjects: {len(TEST_DIRS)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing Train Dataset ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 405/405 [00:22<00:00, 18.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/processed_dl/y_train2.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if not os.path.isfile(join(PROCESSED_DATA_PATH, \"X_train_df.joblib\")):\n",
    "print(f\"\\n\\nProcessing Train Dataset ... \", end='\\n\\n')\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for file_dir in tqdm(TRAIN_DIRS[500:]):\n",
    "    df = pd.read_csv(file_dir)\n",
    "    \n",
    "    if 'Task' in df.columns and 'Valid' in df.columns:\n",
    "        df = df[(df['Valid'] == True) & (df['Task'] == True)]\n",
    "        df = df.drop(['Valid', 'Task'], axis=1).reset_index()\n",
    "\n",
    "    df['label'] = (df['StartHesitation'] * 1) | (df['Turn']\n",
    "                                                 * 2) | (df['Walking'] * 3)\n",
    "    df = df.astype({'label': 'int'})\n",
    "\n",
    "    acc_ap_win, label = get_windowed_data(df['AccAP'].to_numpy(),\n",
    "                                          df['label'].to_numpy(),\n",
    "                                          win_len=100, slide_step=1)\n",
    "    acc_v_win, _ = get_windowed_data(df['AccV'].to_numpy(),\n",
    "                                     df['label'].to_numpy(),\n",
    "                                     win_len=100, slide_step=1)\n",
    "    acc_ml_win, _ = get_windowed_data(df['AccML'].to_numpy(),\n",
    "                                      df['label'].to_numpy(),\n",
    "                                      win_len=100, slide_step=1)\n",
    "\n",
    "    features = np.stack([acc_ap_win, acc_v_win, acc_ml_win], axis=-1)\n",
    "    label = df['label'].to_numpy()\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "\n",
    "X_train = np.concatenate(X_train)\n",
    "y_train = np.concatenate(y_train)\n",
    "dump(X_train, join(PROCESSED_DATA_PATH, \"X_train2.joblib\"))\n",
    "dump(y_train, join(PROCESSED_DATA_PATH, \"y_train2.joblib\"))\n",
    "\n",
    "# else:\n",
    "#     X_train_df = load(join(PROCESSED_DATA_PATH, \"X_train_df.joblib\"))\n",
    "#     X_train = load(join(PROCESSED_DATA_PATH, \"X_train.joblib\"))\n",
    "#     y_train = load(join(PROCESSED_DATA_PATH, \"y_train.joblib\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing Train Dataset ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19/19 [00:00<00:00, 29.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/processed_dl/y_val.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if not os.path.isfile(join(PROCESSED_DATA_PATH, \"X_train_df.joblib\")):\n",
    "print(f\"\\n\\nProcessing Validation Dataset ... \", end='\\n\\n')\n",
    "\n",
    "X_val = []\n",
    "y_val = []\n",
    "\n",
    "for file_dir in tqdm(VAL_DIRS):\n",
    "    df = pd.read_csv(file_dir)\n",
    "\n",
    "    if 'Task' in df.columns and 'Valid' in df.columns:\n",
    "        df = df[(df['Valid'] == True) & (df['Task'] == True)]\n",
    "        df = df.drop(['Valid', 'Task'], axis=1).reset_index()\n",
    "\n",
    "    df['label'] = (df['StartHesitation'] * 1) | (df['Turn']\n",
    "                                                 * 2) | (df['Walking'] * 3)\n",
    "    df = df.astype({'label': 'int'})\n",
    "\n",
    "    acc_ap_win, label = get_windowed_data(df['AccAP'].to_numpy(),\n",
    "                                          df['label'].to_numpy(),\n",
    "                                          win_len=100, slide_step=1)\n",
    "    acc_v_win, _ = get_windowed_data(df['AccV'].to_numpy(),\n",
    "                                     df['label'].to_numpy(),\n",
    "                                     win_len=100, slide_step=1)\n",
    "    acc_ml_win, _ = get_windowed_data(df['AccML'].to_numpy(),\n",
    "                                      df['label'].to_numpy(),\n",
    "                                      win_len=100, slide_step=1)\n",
    "\n",
    "    features = np.stack([acc_ap_win, acc_v_win, acc_ml_win], axis=-1)\n",
    "    label = df['label'].to_numpy()\n",
    "    X_val.append(features)\n",
    "    y_val.append(label)\n",
    "\n",
    "X_val = np.concatenate(X_val)\n",
    "y_val = np.concatenate(y_val)\n",
    "dump(X_val, join(PROCESSED_DATA_PATH, \"X_val.joblib\"))\n",
    "dump(y_val, join(PROCESSED_DATA_PATH, \"y_val.joblib\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing Test Dataset ... \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  4.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../data/processed_dl/X_test.joblib']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# if not os.path.isfile(join(PROCESSED_DATA_PATH, \"X_train_df.joblib\")):\n",
    "print(f\"\\n\\nProcessing Test Dataset ... \", end='\\n\\n')\n",
    "\n",
    "X_test = []\n",
    "\n",
    "for file_dir in tqdm(TEST_DIRS):\n",
    "    df = pd.read_csv(file_dir)\n",
    "\n",
    "    if 'Task' in df.columns and 'Valid' in df.columns:\n",
    "        df = df[(df['Valid'] == True) & (df['Task'] == True)]\n",
    "        df = df.drop(['Valid', 'Task'], axis=1).reset_index()\n",
    "\n",
    "    acc_ap_win, label = get_windowed_data(df['AccAP'].to_numpy(),\n",
    "                                          None,\n",
    "                                          win_len=100, slide_step=1)\n",
    "    acc_v_win, _ = get_windowed_data(df['AccV'].to_numpy(),\n",
    "                                     None,\n",
    "                                     win_len=100, slide_step=1)\n",
    "    acc_ml_win, _ = get_windowed_data(df['AccML'].to_numpy(),\n",
    "                                      None,\n",
    "                                      win_len=100, slide_step=1)\n",
    "\n",
    "    features = np.stack([acc_ap_win, acc_v_win, acc_ml_win], axis=-1)\n",
    "    X_test.append(features)\n",
    "\n",
    "X_test = np.concatenate(X_test)\n",
    "dump(X_test, join(PROCESSED_DATA_PATH, \"X_test.joblib\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
